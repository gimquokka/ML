{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8N/M7j5E1ReVyDkGO3kPs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimquokka/ML/blob/master/ML/Docs_Tutorial/PyTroch/Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaK-hqUG3Tpj",
        "colab_type": "text"
      },
      "source": [
        "# Neural_Networks👍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-ho_Zpn3mPV",
        "colab_type": "text"
      },
      "source": [
        "## Define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9j831Yk38ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4a3bc5fd-cf77-46dd-f2fb-1948585699e2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # 1 input image channel, 6 output chnnels, 2x2 square convolution filter\n",
        "    self.conv1 = nn.Conv2d(1, 8, kernel_size=3 , stride=1)\n",
        "    self.conv2 = nn.Conv2d(8, 16, 2)\n",
        "    # The affine transformation: y = Wx + b\n",
        "    self.fc1 = nn.Linear(16 * 7 * 7, 120)\n",
        "    self.fc2 = nn.Linear(120, 60)\n",
        "    self.fc3 = nn.Linear(60, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    #Max pooling over a (2, 2) window\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.softmax(self.fc3(x), dim = 1) # => Compress output layer \n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIc4qljb38pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d2fcfc2-a58b-4f05-815c-cabe5956b876"
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[7].size())\n",
        "# print(params)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([60])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqdgfcdfNpHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28053d8a-d18a-4dd8-89ce-3c8841c77f05"
      },
      "source": [
        "# Check output dim of conv layer\n",
        "conv1 = nn.Conv2d(1, 8, 3)\n",
        "conv2 = nn.Conv2d(8, 16, 2)\n",
        "\n",
        "a = torch.randn(1, 1, 32, 32)\n",
        "a = F.max_pool2d(F.relu(conv1(a)), 2)\n",
        "a = F.max_pool2d(F.relu(conv2(a)), (2, 2))\n",
        "\n",
        "print(a.size())"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 16, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzWlQaAOL2tS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4195457d-7ea4-4765-cc4e-70b64435e63d"
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "\n",
        "out = net(input)\n",
        "\n",
        "print(out)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0862, 0.0990, 0.0931, 0.1076, 0.1073, 0.0896, 0.1119, 0.1051, 0.0878,\n",
            "         0.1124]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "240aDV-LL2rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WGjcty73lmJ",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuCevy5aUCj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)\n",
        "target = target.view(1, -1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A5RTocJUChx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2e32c095-43d1-46e1-eed4-3f634031f7e7"
      },
      "source": [
        "# grad stack on grad_fn of loss func\n",
        "print(loss.grad_fn)\n",
        "print(loss.grad_fn.next_functions[0][0])\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f4b3cfe4b70>\n",
            "<SoftmaxBackward object at 0x7f4b3cffc278>\n",
            "<AddmmBackward object at 0x7f4b3cfe4b70>\n",
            "<AccumulateGrad object at 0x7f4b3cffc278>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao7lGwH43lj2",
        "colab_type": "text"
      },
      "source": [
        "## Backprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxyXUBp4ZD4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "a56428c8-8ced-4ab9-e244-e4abce5efe86"
      },
      "source": [
        "net.zero_grad()\n",
        "\n",
        "print('Check fc1.bias.grad before backward')\n",
        "print(net.fc1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('Check fc1.bias.grad after backward')\n",
        "print(net.fc1.bias.grad)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check fc1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Check fc1.bias.grad after backward\n",
            "tensor([ 0.0000e+00,  1.4832e-03,  4.1624e-04,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.6503e-04,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1835e-05,\n",
            "         1.2013e-03, -2.9132e-03,  0.0000e+00, -1.6802e-03, -2.7058e-03,\n",
            "        -6.1333e-04, -1.4601e-04,  0.0000e+00,  1.1578e-03,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3581e-03,  7.4985e-04,\n",
            "        -9.8406e-04, -8.0136e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  1.3937e-03,  1.0168e-03,  0.0000e+00,\n",
            "        -4.1720e-04,  1.0311e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  1.1917e-03,  1.6736e-03, -3.8077e-04,\n",
            "         1.2914e-03, -8.5092e-04,  7.6934e-04,  1.1936e-03,  2.8497e-04,\n",
            "         0.0000e+00,  0.0000e+00,  6.6561e-04, -4.5424e-04,  0.0000e+00,\n",
            "         0.0000e+00,  3.5367e-04,  0.0000e+00, -6.4370e-04, -4.7120e-04,\n",
            "         9.6086e-04,  0.0000e+00,  9.5780e-04, -1.9500e-03, -1.8557e-04,\n",
            "         0.0000e+00,  0.0000e+00,  2.7790e-04,  0.0000e+00, -2.3301e-05,\n",
            "         0.0000e+00, -9.3457e-04, -3.7823e-05,  1.3656e-03,  0.0000e+00,\n",
            "         0.0000e+00, -9.0862e-04, -5.9100e-04,  0.0000e+00,  0.0000e+00,\n",
            "        -1.0618e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0010e-04,\n",
            "         8.1943e-04, -3.0055e-03, -1.0778e-03,  0.0000e+00,  1.2876e-03,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4611e-04,\n",
            "         3.2994e-04,  6.4015e-04,  0.0000e+00, -9.8212e-04,  2.2252e-03,\n",
            "         0.0000e+00,  0.0000e+00, -6.9862e-04,  4.2916e-04,  0.0000e+00,\n",
            "         1.2389e-03,  7.3272e-04,  0.0000e+00, -7.3245e-04,  0.0000e+00,\n",
            "         0.0000e+00, -9.1423e-04,  0.0000e+00,  0.0000e+00, -1.4130e-03])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBOKs6IB3lha",
        "colab_type": "text"
      },
      "source": [
        "## Update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW0hMujc3gZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "for f in net.parameters():\n",
        "  '''\n",
        "  Wow... It is really work!\n",
        "  '''\n",
        "  # print(f.data.size())\n",
        "  # print(f.grad.data.size())\n",
        "  f.data.sub_(f.grad.data * learning_rate)\n"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_U4UVGr3gXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f06b2130-b8b7-4cc6-b845-cf30c89c59ff"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step() # This command update parameter base on grad!?"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0000e+00,  1.9066e-03,  1.9323e-04,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -9.2258e-05,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3394e-05,\n",
            "         7.8156e-04, -2.2930e-03,  0.0000e+00, -1.7706e-03, -2.4603e-03,\n",
            "        -5.0006e-04, -7.5663e-04,  0.0000e+00,  2.0372e-03,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5127e-03,  6.5441e-04,\n",
            "        -1.2675e-03, -2.4785e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  1.0365e-03,  1.7540e-03,  0.0000e+00,\n",
            "        -1.6629e-04,  8.3852e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  1.4640e-03,  1.6038e-03,  1.5517e-04,\n",
            "         1.7324e-03, -4.4343e-04,  6.0556e-04,  6.2550e-05, -6.9656e-05,\n",
            "         0.0000e+00,  0.0000e+00,  9.3851e-04,  6.0052e-05,  0.0000e+00,\n",
            "         0.0000e+00,  1.1789e-03,  0.0000e+00, -9.9203e-04, -1.0880e-03,\n",
            "         1.3282e-03,  0.0000e+00,  4.9679e-04, -1.9874e-03, -6.8823e-04,\n",
            "         0.0000e+00,  0.0000e+00,  1.6124e-04,  0.0000e+00,  6.7190e-05,\n",
            "         0.0000e+00, -1.1401e-03, -8.1715e-05,  1.0380e-03,  0.0000e+00,\n",
            "         0.0000e+00, -3.6520e-04, -6.7463e-04,  0.0000e+00,  0.0000e+00,\n",
            "        -1.3795e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.9591e-04,\n",
            "         1.1359e-04, -2.8361e-03, -7.1339e-04,  0.0000e+00,  2.3928e-04,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9808e-05,\n",
            "         1.2883e-04,  1.0722e-03,  0.0000e+00, -1.1752e-03,  1.4231e-03,\n",
            "         0.0000e+00,  0.0000e+00, -1.6060e-03,  3.1522e-04,  0.0000e+00,\n",
            "         9.6851e-04, -2.2988e-04,  0.0000e+00, -9.1226e-04,  0.0000e+00,\n",
            "         0.0000e+00, -1.6863e-03,  0.0000e+00,  0.0000e+00, -1.2914e-03])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}